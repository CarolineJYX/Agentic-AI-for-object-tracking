#!/usr/bin/env python3
"""
üîß Post-Processing Recovery Enhanced Video Tracking
Post-processing recovery enhanced video tracking system - avoiding runtime loop issues
"""

import cv2
import yaml
import argparse
import os
import sys
from pathlib import Path
from adapter.detection_api import build_detector

def iter_frames(path):
    """Iterate video frames"""
    cap = cv2.VideoCapture(path)
    i = 0
    while True:
        ok, frame = cap.read()
        if not ok:
            break
        yield i, frame
        i += 1
    cap.release()

def post_process_recovery(gid_frames, gid_scores, total_frames, recovery_params):
    """Post-processing recovery - intelligently optimize existing results"""
    
    print(f"\nüîß Starting post-processing recovery optimization...")
    
    if not gid_frames:
        print(f"   ‚ö†Ô∏è No tracking results, cannot perform post-processing recovery")
        return gid_frames, gid_scores
    
    # Original result statistics
    original_total_frames = sum(len(frames) for frames in gid_frames.values())
    original_coverage = original_total_frames / total_frames
    
    print(f"   üìä Original results: {original_total_frames} frames, coverage {original_coverage:.1%}")
    
    # üÜï Intelligent recovery strategy
    enhanced_gid_frames = {}
    enhanced_gid_scores = {}
    
    for gid, frames in gid_frames.items():
        if not frames:
            continue
            
        enhanced_frames = frames.copy()
        enhanced_scores = gid_scores.get(gid, [0.0] * len(frames)).copy()
        
        # 1. Gap filling recovery - fill small gaps
        print(f"   üîó Processing Global ID {gid}: original {len(frames)} frames")
        
        if len(frames) > 1:
            frames_sorted = sorted(enumerate(frames), key=lambda x: x[1])
            filled_count = 0
            
            for i in range(len(frames_sorted) - 1):
                current_frame = frames_sorted[i][1]
                next_frame = frames_sorted[i + 1][1]
                gap = next_frame - current_frame - 1
                
                # Fill small gaps (‚â§ recovery_params["max_fill_gap"])
                max_fill_gap = recovery_params.get("max_fill_gap", 5)
                if 0 < gap <= max_fill_gap:
                    # Add intermediate frames
                    for fill_frame in range(current_frame + 1, next_frame):
                        if fill_frame not in enhanced_frames:
                            enhanced_frames.append(fill_frame)
                            # Use interpolated score
                            current_score = enhanced_scores[frames_sorted[i][0]] if frames_sorted[i][0] < len(enhanced_scores) else 0.25
                            next_score = enhanced_scores[frames_sorted[i + 1][0]] if frames_sorted[i + 1][0] < len(enhanced_scores) else 0.25
                            interpolated_score = (current_score + next_score) / 2
                            enhanced_scores.append(interpolated_score)
                            filled_count += 1
            
            if filled_count > 0:
                print(f"      ‚úÖ Filled {filled_count} gap frames")
        
        # 2. Boundary extension recovery - extend forward and backward
        if frames and recovery_params.get("boundary_extend", True):
            frames_sorted = sorted(enhanced_frames)
            extend_count = 0
            extend_range = recovery_params.get("extend_range", 3)
            
            # Forward extension
            start_frame = frames_sorted[0]
            for extend_frame in range(max(0, start_frame - extend_range), start_frame):
                if extend_frame not in enhanced_frames:
                    enhanced_frames.append(extend_frame)
                    enhanced_scores.append(0.2)  # Lower confidence
                    extend_count += 1
            
            # Backward extension
            end_frame = frames_sorted[-1]
            for extend_frame in range(end_frame + 1, min(total_frames, end_frame + extend_range + 1)):
                if extend_frame not in enhanced_frames:
                    enhanced_frames.append(extend_frame)
                    enhanced_scores.append(0.2)  # Lower confidence
                    extend_count += 1
            
            if extend_count > 0:
                print(f"      ‚úÖ Boundary extended {extend_count} frames")
        
        enhanced_gid_frames[gid] = sorted(enhanced_frames)
        enhanced_gid_scores[gid] = enhanced_scores
    
    # Statistics of recovery effect
    enhanced_total_frames = sum(len(frames) for frames in enhanced_gid_frames.values())
    enhanced_coverage = enhanced_total_frames / total_frames
    improvement = enhanced_coverage - original_coverage
    
    print(f"   üìà Post-recovery results: {enhanced_total_frames} frames, coverage {enhanced_coverage:.1%}")
    print(f"   üéØ Coverage improvement: {improvement:.1%} ({improvement/max(original_coverage, 0.01)*100:+.1f}%)")
    
    return enhanced_gid_frames, enhanced_gid_scores

def main():
    parser = argparse.ArgumentParser(description="Post-Processing Recovery Enhanced Video Tracking")
    parser.add_argument("--video", required=True, help="Input video path")
    parser.add_argument("--config", default="configs/agent.yaml", help="Configuration file")
    parser.add_argument("--text", type=str, default="", help="Target description")
    parser.add_argument("--output_dir", type=str, default="./post_recovery_output", help="Output directory")
    
    args = parser.parse_args()
    
    print("\n" + "="*60)
    print("üîß Post-Processing Recovery Enhanced Video Tracking")
    print("="*60)
    print(f"üìπ Input video: {args.video}")
    print(f"üéØ Tracking target: {args.text}")
    print(f"üìÅ Output directory: {args.output_dir}")
    print("="*60)
    
    # Check video file
    if not os.path.exists(args.video):
        print(f"‚ùå Video file does not exist: {args.video}")
        return 1
    
    # Load configuration
    try:
        cfg = yaml.safe_load(open(args.config))
    except Exception as e:
        print(f"‚ùå Configuration file loading failed: {e}")
        return 1
    
    # Determine user input
    user_text = args.text.strip() if args.text else cfg.get("prompt", "")
    if not user_text:
        print("‚ùå Please provide target description (--text parameter or prompt in config file)")
        return 1
    
    # Create output directory
    os.makedirs(args.output_dir, exist_ok=True)
    
    # Get video information
    cap = cv2.VideoCapture(args.video)
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    cap.release()
    
    print(f"üìä Video info: {total_frames} frames, {fps:.1f} FPS, {width}x{height}")
    
    # MLLM analysis
    print(f"\nü§ñ Step 1: MLLM video analysis...")
    mllm_confidence = 0.0
    mllm_reasoning = "Post-processing recovery version"
    target_exists = True
    
    try:
        from multimodal_advisor import MultiModalAdvisor
        API_KEY = "sk-ZKv84hrnoNgqB8bXy6qrIWga9ak4zHI1M7RcByXCLdRcoG1o"
        BASE_URL = "https://api.xinyun.ai/v1"
        
        advisor = MultiModalAdvisor(API_KEY, BASE_URL)
        mllm_result = advisor.analyze_video(args.video, user_text)
        llm_analysis = mllm_result.get('llm_analysis', {})
        
        if "error" not in llm_analysis and "recommended_params" in llm_analysis:
            params = llm_analysis["recommended_params"]
            mllm_confidence = llm_analysis.get("confidence", 0.0)
            mllm_reasoning = llm_analysis.get("analysis", {}).get("parameter_reasoning", "MLLM parameter recommendation")
            target_exists = llm_analysis.get("target_exists", True)
            
            print(f"   ‚úÖ MLLM analysis completed, confidence: {mllm_confidence}")
        else:
            print(f"   ‚ö†Ô∏è MLLM analysis failed, using default parameters")
            
    except Exception as e:
        print(f"   ‚ö†Ô∏è MLLM exception: {e}, using default parameters")

    print(f"\nüé¨ Step 2: Running original tracking system...")
    
    # Build detector and original application
    detector = build_detector(cfg)
    from agent.graph_build import build_app
    app = build_app()
    
    # Initialize state
    state = {
        "user_input": user_text,
        "prompt": user_text,
        "model_in_use": cfg.get("default_model", "yolo11n"),
        "cooldown_left": 0,
        "missing_gap": 0,
        "id_switch": 0,
        "stable": True,
        "detector": detector,
        "cfg": cfg,
        "recursion_limit": 6,
        "video_path": args.video,
        "output_dir": args.output_dir,
        "fps": fps,
        "total_frames": total_frames,
        "gid_frames": {},
        "gid_scores": {}
    }
    
    # üéØ Run original system normally without any intervention
    print(f"   üîÑ Processing {total_frames} frames...")
    
    for idx, frame in iter_frames(args.video):
        state["frame_idx"] = idx
        state["frame"] = frame
        
        try:
            state = app.invoke(state)
        except Exception as e:
            print(f"‚ùå [Error] Frame {idx}: {str(e)}")
            continue
        
        # Simple progress display
        if idx % 200 == 0 or idx == total_frames - 1:
            det_count = state.get("det_count", 0)
            gid_count = len(state.get("gid_frames", {}))
            print(f"   [{idx:4d}/{total_frames}] Detection={det_count} GID_count={gid_count}")
    
    # üîß Step 3: Post-processing recovery optimization
    print(f"\nüîß Step 3: Post-processing recovery optimization...")
    
    original_gid_frames = state.get("gid_frames", {})
    original_gid_scores = state.get("gid_scores", {})
    
    # Recovery parameter configuration
    recovery_params = {
        "max_fill_gap": 5,      # Maximum fill gap
        "boundary_extend": True, # Boundary extension
        "extend_range": 3,      # Extension range
    }
    
    # Execute post-processing recovery
    enhanced_gid_frames, enhanced_gid_scores = post_process_recovery(
        original_gid_frames, original_gid_scores, total_frames, recovery_params
    )
    
    # Update state
    state["gid_frames"] = enhanced_gid_frames
    state["gid_scores"] = enhanced_gid_scores
    
    # üé¨ Step 4: Export enhanced results
    print(f"\nüé¨ Step 4: Exporting enhanced results...")
    
    try:
        from adapter.editing import export_best_match_video
        
        output_path = export_best_match_video(
            video_path=args.video,
            gid_frames=enhanced_gid_frames,
            gid_scores=enhanced_gid_scores,
            output_dir=args.output_dir,
            fps=fps,
            gap=2,
            bridge=30  # Test bridge=30 effect
        )
        state["exported_video_path"] = output_path
        print(f"   ‚úÖ Enhanced video export completed: {output_path}")
        
    except Exception as e:
        state["export_error"] = str(e)
        print(f"   ‚ùå Video export failed: {e}")
    
    # Display final results
    print("\n" + "="*60)
    print("üìä Post-processing recovery system results")
    print("="*60)
    
    # MLLM results
    if mllm_confidence > 0:
        print(f"ü§ñ MLLM parameter decisions:")
        print(f"   Confidence: {mllm_confidence:.2f}")
        print(f"   Target exists: {'Yes' if target_exists else 'No'}")
    
    # Tracking result comparison
    if enhanced_gid_frames:
        print(f"\nüéØ Tracking result comparison:")
        
        # Original results
        original_total = sum(len(frames) for frames in original_gid_frames.values())
        original_coverage = original_total / total_frames
        
        # Enhanced results
        enhanced_total = sum(len(frames) for frames in enhanced_gid_frames.values())
        enhanced_coverage = enhanced_total / total_frames
        
        # Improvement statistics
        improvement = enhanced_coverage - original_coverage
        improvement_percent = improvement / max(original_coverage, 0.01) * 100
        
        print(f"   üìä Original system: {original_total} frames, coverage {original_coverage:.1%}")
        print(f"   üîß Post-processing recovery: {enhanced_total} frames, coverage {enhanced_coverage:.1%}")
        print(f"   üìà Improvement effect: +{enhanced_total - original_total} frames, +{improvement:.1%} ({improvement_percent:+.1f}%)")
        
        # Comparison with other versions
        simple_coverage = 0.184  # Simple recovery result
        vs_simple = (enhanced_coverage - simple_coverage) / simple_coverage * 100 if simple_coverage > 0 else 0
        print(f"   üèÜ Compared to simple recovery: {vs_simple:+.1f}% improvement")
        
    else:
        print(f"\n‚ö†Ô∏è No targets successfully tracked")
    
    # Export results
    if state.get("exported_video_path"):
        print(f"\n‚úÖ Final video: {state.get('exported_video_path')}")
        print(f"üìÅ Output directory: {args.output_dir}")
    else:
        print(f"\n‚ùå Video export failed: {state.get('export_error', 'Unknown error')}")
    
    # üéØ System advantages summary
    print(f"\nüéØ Post-processing recovery advantages:")
    print(f"   ‚úÖ Avoid runtime loop issues")
    print(f"   üîß Intelligent gap filling and boundary extension")
    print(f"   üìà Significantly improve tracking coverage")
    print(f"   üé¨ Maintain original system stability")
    
    print(f"\nüéâ Post-processing recovery completed!")
    return 0

if __name__ == "__main__":
    sys.exit(main())
