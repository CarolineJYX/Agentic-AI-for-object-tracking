# ğŸ¯ Agentic AI for Video Object Tracking

> **A pioneering multi-modal AI system that autonomously optimizes video object tracking parameters through intelligent agent-based decision making.**

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![LangGraph](https://img.shields.io/badge/LangGraph-enabled-green.svg)](https://github.com/langchain-ai/langgraph)
[![Multi-Modal](https://img.shields.io/badge/Multi--Modal-CLIP%2BLLM-orange.svg)](https://github.com/mlfoundations/open_clip)

## ğŸŒŸ Key Innovation

This project introduces the **first Agentic AI approach** to video object tracking, where AI agents autonomously analyze video content and optimize tracking parameters without manual tuning.

## ğŸ—ï¸ Architecture Overview

```
ğŸ–¥ï¸  User Interface Layer
    â”œâ”€â”€ agent_main.py              # Traditional System  
    â””â”€â”€ agent_main_mllm.py         # MLLM-Enhanced System

ğŸ§   Agent Layer (Decision & Strategy)
    â”œâ”€â”€ agent/planner.py           # Parameter Optimization
    â”œâ”€â”€ agent/policies.py          # Decision Policies
    â”œâ”€â”€ multimodal_advisor.py      # MLLM-based Analysis
    â””â”€â”€ agent/state_types.py       # State Management

ğŸ”§  Adapter Layer (Tool Implementation)  
    â”œâ”€â”€ adapter/detection_api.py   # YOLO Integration
    â”œâ”€â”€ adapter/tracking.py        # ByteTrack Wrapper
    â”œâ”€â”€ adapter/clip_matcher.py    # Semantic Matching
    â”œâ”€â”€ adapter/editing.py         # Video Processing
    â””â”€â”€ adapter/global_id.py       # Identity Management

âš™ï¸  Foundation Layer
    â”œâ”€â”€ tracker/                   # ByteTrack Implementation
    â””â”€â”€ configs/                   # System Configuration
```

For detailed architecture documentation, see [ARCHITECTURE.md](./ARCHITECTURE.md).

## ğŸš€ Features

- **ğŸ¯ Semantic Object Tracking**: Natural language description to video object mapping
- **ğŸ§  Intelligent Decision Making**: Dynamic parameter adjustment based on video analysis  
- **ğŸ”— Multi-Modal Integration**: YOLO + ByteTrack + CLIP + LangGraph
- **ğŸ“Š Global Identity Management**: Consistent object tracking across frames
- **ğŸ¬ Intelligent Video Editing**: Automatic segment merging with bridge algorithms
- **âš¡ Performance Optimization**: Model caching and batch processing

## ğŸ› ï¸ Technology Stack

- **Computer Vision**: YOLOv11, ByteTrack
- **Multi-Modal AI**: OpenCLIP  
- **Workflow Orchestration**: LangGraph
- **Video Processing**: OpenCV, MoviePy
- **Architecture Pattern**: Agent-Adapter Separation

## ğŸ“¦ Installation

```bash
# Create conda environment
conda create -n capstone310 python=3.10
conda activate capstone310

# Install dependencies
pip install ultralytics
pip install open-clip-torch
pip install langgraph
pip install opencv-python
pip install moviepy
```

## ğŸ® Usage

### ğŸ¤– MLLM-Enhanced System (Recommended)
```bash
# Intelligent parameter optimization with multi-modal LLM
python agent_main_mllm.py --video demo2.mp4 --text "track the woman in white clothes dancing" --output_dir ./output_mllm
```

### ğŸ”§ Traditional System (For Comparison)
```bash
# Manual parameter configuration
python agent_main.py --video demo2.mp4 --text "track the woman in white clothes dancing" --output_dir ./output_traditional
```

### ğŸ“Š Key Differences

| Feature | Traditional System | MLLM-Enhanced System |
|---------|-------------------|---------------------|
| **Parameter Tuning** | Manual configuration | Fully automated |
| **Video Analysis** | Rule-based | AI-powered analysis |
| **Target Detection** | Basic matching | Semantic understanding |
| **Adaptation** | Static parameters | Dynamic optimization |
| **User Experience** | Technical expertise required | Natural language input |

### Parameters
- `--video`: Input video file path
- `--text`: Natural language description of target object  
- `--output_dir`: Output directory for processed video

## ğŸ§  System Workflow

1. **Detection**: YOLO identifies potential objects in each frame
2. **Tracking**: ByteTrack maintains object trajectories across frames  
3. **Semantic Matching**: CLIP matches objects to text description
4. **Global Identity**: Assigns consistent IDs to tracked objects
5. **Intelligent Planning**: Dynamically adjusts parameters based on video characteristics
6. **Video Editing**: Merges tracking segments and exports final video

## ğŸ“Š Key Components

### Agent Layer (Decision Logic)
- **Planner**: Dynamic strategy adjustment (bridge values, thresholds)
- **State Manager**: Unified state management across workflow nodes
- **Global ID Manager**: Object identity consistency

### Adapter Layer (Tool Implementation)  
- **Detection Adapter**: YOLO model integration
- **Tracking Adapter**: ByteTrack algorithm wrapper
- **CLIP Adapter**: Multi-modal semantic matching
- **Editing Adapter**: Video processing and export

### LangGraph Orchestration
- **Stateful Workflow**: Node-based processing pipeline
- **Dynamic Routing**: Conditional workflow paths
- **Error Handling**: Robust error recovery mechanisms

## ğŸ¯ Academic Contributions

- **Agent-Adapter Architecture**: Clean separation of concerns for AI systems
- **Multi-Modal Integration**: Seamless combination of vision and language models
- **Dynamic Parameter Optimization**: Intelligent adaptation to video characteristics
- **Global Identity Management**: Novel approach to cross-frame object consistency

## ğŸ“ˆ Performance Features

- **Model Caching**: Avoid repeated model loading
- **Batch Processing**: Efficient frame processing
- **Memory Optimization**: Intelligent state management
- **Adaptive Thresholding**: Dynamic quality control

## ğŸ”¬ Research Applications

This system demonstrates:
- **Agentic AI Principles**: Autonomous decision-making and adaptation
- **Multi-Modal AI Integration**: Vision-language model coordination  
- **Workflow Orchestration**: Complex AI system management
- **Real-World Problem Solving**: Practical video processing challenges

## ğŸ“ Citation

If you use this work in your research, please cite:

```bibtex
@misc{agentic_video_tracking_2024,
  title={Agentic Video Object Tracking and Editing System},
  author={[Your Name]},
  year={2024},
  note={Master's Thesis Project}
}
```

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“§ Contact

For questions or collaborations, please contact: [Your Email]
